{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Demo Sidang TA II.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Rb1J_JfZtPSr8zgrH6v32ueZM-P2HCl5",
      "authorship_tag": "ABX9TyMi/xhyziXbk/so8oNy9vgg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB36OXLT6PS1"
      },
      "source": [
        "# Opinion Triplet Extraction || Aspect Sentiment Triplet Extraction\n",
        "<a href=\"https://colab.research.google.com/github/gamapradipta/aste/blob/development/src/notebook/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj3t6t6KyAZU"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5srlyatjzIy"
      },
      "source": [
        "# !rm -r aste"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_ezqnnYvfDg"
      },
      "source": [
        "!git clone -b development https://github.com/gamapradipta/aste"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EoX44GUemaz"
      },
      "source": [
        "!git -C aste status"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f0iUq6W02Y4"
      },
      "source": [
        "!git -C aste pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhoYZv6JxFte"
      },
      "source": [
        "import sys\n",
        "\n",
        "sys.path.insert(0, '/content/aste/src/model')\n",
        "sys.path.insert(0, '/content/aste/src')\n",
        "sys.path.insert(0, '/content/aste/data')\n",
        "sys.path.insert(0, '/content/aste')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxpCuAhzy_m4"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2y1doZk4nl2"
      },
      "source": [
        "import tensorflow as tf\n",
        "gpu = tf.config.list_physical_devices('GPU')\n",
        "print(\"Num GPUs Available: \", len(gpu))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pLtHO_ayFZn"
      },
      "source": [
        "## Import and Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7Jlu0Zahm-E"
      },
      "source": [
        "### Import & Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXSS5Pgnxqr4"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import argparse\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "from model.data import SentenceExample, create_inputs_targets, create_sentence_example, BaseSentence\n",
        "from model.config import Config\n",
        "from model.model import ASTE\n",
        "\n",
        "tf.random.set_seed(1234)\n",
        "\n",
        "#@title Configuration { display-mode: \"form\" }\n",
        "model_name = \"model_888\" #@param {type:\"string\"}\n",
        "fine_tuned = True #@param {type:\"boolean\"}\n",
        "bert_version = \"indobenchmark/indobert-base-p1\" #@param [\"bert-base-multilingual-cased\", \"indobenchmark/indobert-base-p1\", \"bert-base-multilingual-uncased\"]\n",
        "data_cleaned = False #@param {type:\"boolean\"}\n",
        "max_len =  170#@param {type:\"number\"}\n",
        "\n",
        "model_type = {\n",
        "    \"bert-base-multilingual-cased\" : \"multilingual\",\n",
        "    \"bert-base-multilingual-uncased\" : \"multilingual\",\n",
        "    \"indobenchmark/indobert-base-p1\" : \"monolingual\"\n",
        "}\n",
        "\n",
        "def check_fine_tuned(fine_tuned):\n",
        "  if fine_tuned:\n",
        "    return \"finetuned\"\n",
        "  return \"featextract\"\n",
        "\n",
        "def check_data_cleaned(data_cleaned):\n",
        "  if data_cleaned:\n",
        "    return \"cleaned\"\n",
        "  return \"uncleaned\"\n",
        "\n",
        "model_save_name = \"{}_{}_{}_{}_{}\".format(model_name,\n",
        "                                          check_data_cleaned(data_cleaned),\n",
        "                                          model_type.get(bert_version, \"unknown\"),\n",
        "                                          check_fine_tuned(fine_tuned),\n",
        "                                          max_len)\n",
        "print(model_save_name)\n",
        "\n",
        "\n",
        "config = Config()\n",
        "config.max_len = max_len\n",
        "config.fine_tuned = fine_tuned\n",
        "config.bert_version = bert_version\n",
        "tokenizer = BertTokenizer.from_pretrained(config.bert_version)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHgzJhi2RVJJ"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tygji_B-4uu4"
      },
      "source": [
        "#### Prep Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c37rf1574x-a"
      },
      "source": [
        "%%bash\n",
        "cd /content/aste/src/data\n",
        "\n",
        "python parse.py \\\n",
        "--dataset hotel \\\n",
        "--input raw/ \\\n",
        "--output interim/ \\\n",
        "--mode parse_all\n",
        "\n",
        "python parse.py \\\n",
        "--dataset hotel \\\n",
        "--input interim/ \\\n",
        "--output processed/ \\\n",
        "--mode remove_unvalid_data_json\n",
        "\n",
        "\n",
        "cp /content/aste/data/interim/hotel/test.json /content/aste/data/processed/hotel\n",
        "cp /content/aste/data/interim/hotel/validation.json /content/aste/data/processed/hotel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my9Bkw08hefi"
      },
      "source": [
        "#### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mY-P-f2qgdPs"
      },
      "source": [
        "if data_cleaned:\n",
        "  BASE_DATA_DIR = '/content/aste/data/processed/hotel/'\n",
        "else:\n",
        "  BASE_DATA_DIR = '/content/aste/data/interim/hotel/'"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNg8Bp-1yZbz"
      },
      "source": [
        "TRAIN_DATA_DIR = os.path.join(BASE_DATA_DIR, 'train.json')  \n",
        "\n",
        "train_examples = create_sentence_example(TRAIN_DATA_DIR, tokenizer, config)\n",
        "X_train, y_train = create_inputs_targets(train_examples)\n",
        "\n",
        "print(X_train[0].shape, X_train[1].shape)\n",
        "print(y_train[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZM4vh9mlKWJ"
      },
      "source": [
        "TEST_DATA_DIR = os.path.join(BASE_DATA_DIR, 'test.json')\n",
        "\n",
        "test_examples = create_sentence_example(TEST_DATA_DIR, tokenizer, config)\n",
        "X_test, y_test, token_ranges_test = create_inputs_targets(test_examples, include_token_ranges=True)\n",
        "\n",
        "print(X_test[0].shape, X_test[1].shape)\n",
        "print(y_test[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa8zumi8giv_"
      },
      "source": [
        "VALID_DATA_DIR = os.path.join(BASE_DATA_DIR, 'validation.json')\n",
        "\n",
        "valid_examples = create_sentence_example(VALID_DATA_DIR, tokenizer, config)\n",
        "X_valid, y_valid, token_ranges_valid = create_inputs_targets(valid_examples, include_token_ranges=True)\n",
        "\n",
        "print(X_valid[0].shape, X_valid[1].shape)\n",
        "print(y_valid[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dguYpuR69Sr"
      },
      "source": [
        "## Additional Function for Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7PjGmz668lr"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def get_text_color(n):\n",
        "  if n == 1:\n",
        "    return 'r'\n",
        "  if n == 2:\n",
        "    return 'b'\n",
        "  if n == 3:\n",
        "    return 'm'\n",
        "  if n == 4:\n",
        "    return 'm'\n",
        "  if n == 5:\n",
        "    return 'm'\n",
        "  if n== 0:\n",
        "    return 'k'\n",
        "\n",
        "def plot_tag(tag, token=None, max=None, triu=True):\n",
        "  if not max or max==0:\n",
        "    max = len(tag[0])\n",
        "  if max > len(tag[0]):\n",
        "    max = len(tag[0])\n",
        "\n",
        "  show_tag = tag[:max, :max]\n",
        "  if token:\n",
        "    show_token = token[:max]\n",
        "  colors = 'gray lime purple green red yellow'.split()\n",
        "  colors = 'white'.split()\n",
        "  cmap = matplotlib.colors.ListedColormap(colors, name='colors', N=None)\n",
        "\n",
        "  if triu:\n",
        "    show_tag = np.triu(show_tag)\n",
        "\n",
        "  fig, ax = plt.subplots( figsize=(max/2, max/2))\n",
        "  im = ax.imshow(show_tag,cmap=cmap)\n",
        "\n",
        "  if token:\n",
        "    ax.set_xticks(np.arange(len(show_token)))\n",
        "    ax.set_yticks(np.arange(len(show_token)))\n",
        "    ax.set_xticklabels(show_token)\n",
        "    ax.set_yticklabels(show_token)\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "         rotation_mode=\"anchor\")\n",
        "  \n",
        "  for i in range(len(show_tag[0])):\n",
        "    for j in range(len(show_tag[0])):\n",
        "      if triu and j<i:\n",
        "          continue\n",
        "      text = ax.text(j, i, show_tag[i, j],\n",
        "                       ha=\"center\", va=\"center\", color=get_text_color(show_tag[i,j]), weight='bold')\n",
        "  plt.show()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zhq5_cRJ2y08"
      },
      "source": [
        "## Model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2CXnHr_3GJ3"
      },
      "source": [
        "### Model Init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj7l2BtY2w4t"
      },
      "source": [
        "aste = ASTE(config)\n",
        "aste.init_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm9JQ7cZNO2U"
      },
      "source": [
        "aste.model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7Cd8upi3JW1"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PZzDng43HpG"
      },
      "source": [
        "#@title HYPERPARAM TRAINING\n",
        "batch_size =  10#@param {type:\"integer\"}\n",
        "epochs =  10#@param {type:\"integer\"}\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "if gpu:\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    aste.train(X_train,\n",
        "              y_train,\n",
        "              batch_size=batch_size,\n",
        "              verbose=1,\n",
        "              epochs=epochs,\n",
        "              X_val=X_valid,\n",
        "              y_val=y_valid\n",
        "              )\n",
        "else:\n",
        "  aste.train(X_train,\n",
        "              y_train,\n",
        "              batch_size=batch_size,\n",
        "              verbose=1,\n",
        "              epochs=epochs,\n",
        "              X_val=X_valid,\n",
        "              y_val=y_valid\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGQ3IZogHl7X"
      },
      "source": [
        "### Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTKHpmVKD4vo"
      },
      "source": [
        "BASE_MODEL_PATH = \"/content/ASTE/saved_model/\"\n",
        "MODEL_PATH = os.path.join(BASE_MODEL_PATH, model_save_name, \"model\")\n",
        "\n",
        "aste.save_model(MODEL_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_yAgVjmrI7N"
      },
      "source": [
        "### Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypvrXMUmYbhw"
      },
      "source": [
        "BASE_MODEL_PATH = \"/content/ASTE/saved_model/\"\n",
        "MODEL_PATH = os.path.join(BASE_MODEL_PATH, model_save_name, \"model\")\n",
        "\n",
        "aste.init_model()\n",
        "aste.load_model(MODEL_PATH)\n",
        "aste.model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy6_Ajj5KZnt"
      },
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0VOHIh9LE6H"
      },
      "source": [
        "#### Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZB4R-etk-V7"
      },
      "source": [
        "aste.evaluate(X_valid, y_valid[0], token_ranges_valid[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgHgGmh1LHsi"
      },
      "source": [
        "#### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmjfYmyPlH3g"
      },
      "source": [
        "aste.evaluate(X_test, y_test[0], token_ranges_test[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFzo1yQvGBoY"
      },
      "source": [
        "# DEMO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U5-LnCtGBFX",
        "cellView": "form"
      },
      "source": [
        "#@title DEMO\n",
        "Ulasan = \"kamar mandi sangat bersih tetapi tamannya sangat kotor\" #@param [\"Hotel bersih , fasilitas lengkap , tapi sarapan kurang enak\", \"kamarnya luas dan bersih , tapi toilet dan taman tidak bersih\", \"cukup bersih dan wifi okelah .\", \"bagus tapi mahal kamarnya\", \"bersih dan luas kamarnya , tapi toiletnya kotor dan menjijikan\", \"kamar sangat bersih dan nyaman , hotel bersih , akan lebih baik ada hair dryer di kamar\"] {allow-input: true}\n",
        "# example = train_examples[0]\n",
        "temp = \"luas dan bersih kamarnya , toilet dan taman bersih sekali \"\n",
        "sentence_pack = {\n",
        "    \"sentence\" : Ulasan\n",
        "}\n",
        "aste.model.run_eagerly=True\n",
        "with tf.device('/GPU:0') :\n",
        "  example = BaseSentence(sentence_pack, tokenizer, config)\n",
        "\n",
        "triples, aspects, sentiments = aste.predict_one(example, example.token_ranges, triple_only=False)\n",
        "print(\"TRIPLES\")\n",
        "for triple in triples:\n",
        "  print(triple)\n",
        "print(\"---------------------------------------------\")\n",
        "print(\"ASPECTS\")\n",
        "for aspect in aspects:\n",
        "  print(aspect)\n",
        "print(\"---------------------------------------------\")\n",
        "print(\"SENTIMENTS\")\n",
        "for sentiment in sentiments:\n",
        "  print(sentiment)\n",
        "print(\"---------------------------------------------\")\n",
        "\n",
        "pred = aste.predict(example.get_X(), logits=False)[0]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqRo8ka8GKsJ",
        "cellView": "form"
      },
      "source": [
        "last_tag_num = example.token_ranges[-1][-1]+2\n",
        "\n",
        "#@title DEMO TAG VISUALIZATION\n",
        "# last_tag = True #@param {type:\"boolean\"}\n",
        "max_len =  0#@param {type:\"integer\"}\n",
        "with_token = True #@param {type:\"boolean\"}\n",
        "triu = True #@param {type:\"boolean\"}\n",
        "include_pad = False #@param {type:\"boolean\"}\n",
        "\n",
        "token = tokenizer.convert_ids_to_tokens(example.input_ids) if with_token else None\n",
        "\n",
        "first, last = example.token_ranges[0][-1],  example.token_ranges[-1][-1]+1\n",
        "\n",
        "# print(first, last)\n",
        "\n",
        "show_pred = pred\n",
        "show_token = token\n",
        "\n",
        "if not include_pad:\n",
        "  show_pred = pred[first:last, first:last]\n",
        "  show_token = token[first:last] if with_token else None\n",
        "\n",
        "\n",
        "plot_tag(show_pred, show_token,max_len ,triu=triu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMUBs_HKOyTS"
      },
      "source": [
        "# Terima Kasih :)"
      ]
    }
  ]
}